{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import time, gc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "train_1 = pd.read_csv('training-set.csv',dtype={'order_id':str})\n",
    "test_1 = pd.read_csv('testing-set.csv',dtype={'order_id':str})\n",
    "order = pd.read_pickle('order1421_newfillna.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "train_1=train.merge(order,on='order_id')\n",
    "test_1=test.merge(order,on='order_id')\n",
    "folds = StratifiedKFold(n_splits= 5, shuffle=True, random_state=666)\n",
    "oof_preds = np.zeros((train_1.shape[0],6))\n",
    "sub_preds = np.zeros((test_1.shape[0],6))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "feats = [f for f in train_1.columns if f not in ['order_id','deal_or_not','order_date','begin_date','return_date']]\n",
    "print ('feats:' + str(len(feats)),feats)\n",
    "time.time()-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_1[feats], train_1['deal_or_not'])):\n",
    "    train_x, train_y = train_1[feats].iloc[train_idx], train_1['deal_or_not'].iloc[train_idx]\n",
    "    valid_x, valid_y = train_1[feats].iloc[valid_idx], train_1['deal_or_not'].iloc[valid_idx]\n",
    "    print(\"Train Index:\",train_idx,\",Val Index:\",valid_idx)\n",
    "\n",
    "    params = {\n",
    "    'nthread': 32,\n",
    "    'boosting_type': 'dart',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 100,\n",
    "    'max_depth': 8,\n",
    "    'feature_fraction': 0.7,\n",
    "    'min_split_gain': 0.1,\n",
    "    'min_data_in_leaf': 100,\n",
    "    'min_child_weight': 0.01,\n",
    "    'reg_alpha': 10,\n",
    "    'reg_lambda': 10,\n",
    "# parameters for dart\n",
    "#     'drop_rate':0.1,\n",
    "#     'skip_drop':0.5,\n",
    "    'max_drop':100,\n",
    "    'uniform_drop':False,\n",
    "    'xgboost_dart_mode':False,\n",
    "#     'drop_seed':4\n",
    "    }\n",
    "\n",
    "    if n_fold >= 0:\n",
    "        dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "        dval = lgb.Dataset(valid_x, label=valid_y, reference=dtrain)\n",
    "        \n",
    "        bst = lgb.train(\n",
    "        params, dtrain, num_boost_round=5000,\n",
    "        valid_sets=[dval], early_stopping_rounds=500, verbose_eval=100)\n",
    "        oof_preds[valid_idx,0] = bst.predict(valid_x, num_iteration=bst.best_iteration)\n",
    "        sub_preds[:,0] += bst.predict(test_1[feats], num_iteration=bst.best_iteration) / folds.n_splits\n",
    "        # Make the feature importance dataframe\n",
    "        gain = bst.feature_importance('gain')\n",
    "        fold_importance_df = pd.DataFrame({'feature':bst.feature_name(),\n",
    "        'split':bst.feature_importance('split'),\n",
    "        'gain':100*gain/gain.sum(),\n",
    "        'fold':n_fold,\n",
    "        }).sort_values('gain',ascending=False)\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "#         print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx,0])))\n",
    "time.time()-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.753232 0.757929 0.753538 0.755814 0.756462"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_1[feats], train_1['deal_or_not'])):\n",
    "    train_x, train_y = train_1[feats].iloc[train_idx], train_1['deal_or_not'].iloc[train_idx]\n",
    "    valid_x, valid_y = train_1[feats].iloc[valid_idx], train_1['deal_or_not'].iloc[valid_idx]\n",
    "    print(\"Train Index:\",train_idx,\",Val Index:\",valid_idx)\n",
    "\n",
    "    params = {\n",
    "    'nthread': 32,\n",
    "    'boosting_type': 'dart',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 100,\n",
    "    'max_depth': 8,\n",
    "    'feature_fraction': 0.7,\n",
    "    'min_split_gain': 0.1,\n",
    "    'min_data_in_leaf': 100,\n",
    "    'min_child_weight': 0.01,\n",
    "    'reg_alpha': 10,\n",
    "    'reg_lambda': 10,\n",
    "# parameters for dart\n",
    "#     'drop_rate':0.1,\n",
    "#     'skip_drop':0.5,\n",
    "    'max_drop':100,\n",
    "    'uniform_drop':False,\n",
    "    'xgboost_dart_mode':True,\n",
    "#     'drop_seed':4\n",
    "    }\n",
    "\n",
    "    if n_fold >= 0:\n",
    "        dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "        dval = lgb.Dataset(valid_x, label=valid_y, reference=dtrain)\n",
    "        \n",
    "        bst = lgb.train(\n",
    "        params, dtrain, num_boost_round=5000,\n",
    "        valid_sets=[dval], early_stopping_rounds=500, verbose_eval=100)\n",
    "        oof_preds[valid_idx,1] = bst.predict(valid_x, num_iteration=bst.best_iteration)\n",
    "        sub_preds[:,1] += bst.predict(test_1[feats], num_iteration=bst.best_iteration) / folds.n_splits\n",
    "        # Make the feature importance dataframe\n",
    "        gain = bst.feature_importance('gain')\n",
    "        fold_importance_df = pd.DataFrame({'feature':bst.feature_name(),\n",
    "        'split':bst.feature_importance('split'),\n",
    "        'gain':100*gain/gain.sum(),\n",
    "        'fold':n_fold,\n",
    "        }).sort_values('gain',ascending=False)\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "#         print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx,0])))\n",
    "time.time()-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.751736 0.755271 0.75038 0.753552 0.754325"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_1[feats], train_1['deal_or_not'])):\n",
    "    train_x, train_y = train_1[feats].iloc[train_idx], train_1['deal_or_not'].iloc[train_idx]\n",
    "    valid_x, valid_y = train_1[feats].iloc[valid_idx], train_1['deal_or_not'].iloc[valid_idx]\n",
    "    print(\"Train Index:\",train_idx,\",Val Index:\",valid_idx)\n",
    "\n",
    "    params = {\n",
    "    'nthread': 32,\n",
    "    'boosting_type': 'dart',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 100,\n",
    "    'max_depth': 8,\n",
    "    'feature_fraction': 0.7,\n",
    "    'min_split_gain': 0.1,\n",
    "    'min_data_in_leaf': 100,\n",
    "    'min_child_weight': 0.01,\n",
    "    'reg_alpha': 10,\n",
    "    'reg_lambda': 10,\n",
    "# parameters for dart\n",
    "#     'drop_rate':0.1,\n",
    "#     'skip_drop':0.5,\n",
    "    'max_drop':100,\n",
    "    'uniform_drop':True,\n",
    "    'xgboost_dart_mode':False,\n",
    "#     'drop_seed':4\n",
    "    }\n",
    "\n",
    "    if n_fold >= 0:\n",
    "        dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "        dval = lgb.Dataset(valid_x, label=valid_y, reference=dtrain)\n",
    "        \n",
    "        bst = lgb.train(\n",
    "        params, dtrain, num_boost_round=5000,\n",
    "        valid_sets=[dval], early_stopping_rounds=500, verbose_eval=100)\n",
    "        oof_preds[valid_idx,2] = bst.predict(valid_x, num_iteration=bst.best_iteration)\n",
    "        sub_preds[:,2] += bst.predict(test_1[feats], num_iteration=bst.best_iteration) / folds.n_splits\n",
    "        # Make the feature importance dataframe\n",
    "        gain = bst.feature_importance('gain')\n",
    "        fold_importance_df = pd.DataFrame({'feature':bst.feature_name(),\n",
    "        'split':bst.feature_importance('split'),\n",
    "        'gain':100*gain/gain.sum(),\n",
    "        'fold':n_fold,\n",
    "        }).sort_values('gain',ascending=False)\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "#         print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx,0])))\n",
    "time.time()-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.752523 0.757315 0.753433 0.756181 0.756143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_1[feats], train_1['deal_or_not'])):\n",
    "    train_x, train_y = train_1[feats].iloc[train_idx], train_1['deal_or_not'].iloc[train_idx]\n",
    "    valid_x, valid_y = train_1[feats].iloc[valid_idx], train_1['deal_or_not'].iloc[valid_idx]\n",
    "    print(\"Train Index:\",train_idx,\",Val Index:\",valid_idx)\n",
    "\n",
    "    params = {\n",
    "    'nthread': 32,\n",
    "    'boosting_type': 'dart',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 100,\n",
    "    'max_depth': 8,\n",
    "    'feature_fraction': 0.7,\n",
    "    'min_split_gain': 0.1,\n",
    "    'min_data_in_leaf': 100,\n",
    "    'min_child_weight': 0.01,\n",
    "    'reg_alpha': 10,\n",
    "    'reg_lambda': 10,\n",
    "# parameters for dart\n",
    "#     'drop_rate':0.1,\n",
    "#     'skip_drop':0.5,\n",
    "    'max_drop':100,\n",
    "    'uniform_drop':True,\n",
    "    'xgboost_dart_mode':True,\n",
    "#     'drop_seed':4\n",
    "    }\n",
    "\n",
    "    if n_fold >= 0:\n",
    "        dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "        dval = lgb.Dataset(valid_x, label=valid_y, reference=dtrain)\n",
    "        \n",
    "        bst = lgb.train(\n",
    "        params, dtrain, num_boost_round=5000,\n",
    "        valid_sets=[dval], early_stopping_rounds=500, verbose_eval=100)\n",
    "        oof_preds[valid_idx,3] = bst.predict(valid_x, num_iteration=bst.best_iteration)\n",
    "        sub_preds[:,3] += bst.predict(test_1[feats], num_iteration=bst.best_iteration) / folds.n_splits\n",
    "        # Make the feature importance dataframe\n",
    "        gain = bst.feature_importance('gain')\n",
    "        fold_importance_df = pd.DataFrame({'feature':bst.feature_name(),\n",
    "        'split':bst.feature_importance('split'),\n",
    "        'gain':100*gain/gain.sum(),\n",
    "        'fold':n_fold,\n",
    "        }).sort_values('gain',ascending=False)\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "#         print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx,0])))\n",
    "time.time()-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.75104 0.755004 0.750773 0.753097 0.753949"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_1[feats], train_1['deal_or_not'])):\n",
    "    train_x, train_y = train_1[feats].iloc[train_idx], train_1['deal_or_not'].iloc[train_idx]\n",
    "    valid_x, valid_y = train_1[feats].iloc[valid_idx], train_1['deal_or_not'].iloc[valid_idx]\n",
    "    print(\"Train Index:\",train_idx,\",Val Index:\",valid_idx)\n",
    "\n",
    "    params = {\n",
    "    'nthread': 32,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 100,\n",
    "    'max_depth': 8,\n",
    "    'feature_fraction': 0.7,\n",
    "    'min_split_gain': 0.1,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'min_child_weight': 0.01,\n",
    "    'reg_alpha': 10,\n",
    "    'reg_lambda': 10\n",
    "    }\n",
    "\n",
    "    if n_fold >= 0:\n",
    "        dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "        dval = lgb.Dataset(valid_x, label=valid_y, reference=dtrain)\n",
    "        \n",
    "        bst = lgb.train(\n",
    "        params, dtrain, num_boost_round=5000,\n",
    "        valid_sets=[dval], early_stopping_rounds=500, verbose_eval=100)\n",
    "        oof_preds[valid_idx,4] = bst.predict(valid_x, num_iteration=bst.best_iteration)\n",
    "        sub_preds[:,4] += bst.predict(test_1[feats], num_iteration=bst.best_iteration) / folds.n_splits\n",
    "        # Make the feature importance dataframe\n",
    "        gain = bst.feature_importance('gain')\n",
    "        fold_importance_df = pd.DataFrame({'feature':bst.feature_name(),\n",
    "        'split':bst.feature_importance('split'),\n",
    "        'gain':100*gain/gain.sum(),\n",
    "        'fold':n_fold,\n",
    "        }).sort_values('gain',ascending=False)\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "#         print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx,0])))\n",
    "time.time()-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.750171 0.7544 0.75046 0.753191 0.75456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_1[feats], train_1['deal_or_not'])):\n",
    "    train_x, train_y = train_1[feats].iloc[train_idx], train_1['deal_or_not'].iloc[train_idx]\n",
    "    valid_x, valid_y = train_1[feats].iloc[valid_idx], train_1['deal_or_not'].iloc[valid_idx]\n",
    "    print(\"Train Index:\",train_idx,\",Val Index:\",valid_idx)\n",
    "\n",
    "    params = {\n",
    "    'nthread': 32,\n",
    "    'boosting_type': 'rf',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 100,\n",
    "    'max_depth': 8,\n",
    "    'feature_fraction': 0.7,\n",
    "    'bagging_fraction':0.9,\n",
    "    'bagging_freq':100,\n",
    "    'min_split_gain': 0.1,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'min_child_weight': 0.01,\n",
    "    'reg_alpha': 10,\n",
    "    'reg_lambda': 10\n",
    "    }\n",
    "\n",
    "    if n_fold >= 0:\n",
    "        dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "        dval = lgb.Dataset(valid_x, label=valid_y, reference=dtrain)\n",
    "        \n",
    "        bst = lgb.train(\n",
    "        params, dtrain, num_boost_round=5000,\n",
    "        valid_sets=[dval], early_stopping_rounds=500, verbose_eval=100)\n",
    "        oof_preds[valid_idx,5] = bst.predict(valid_x, num_iteration=bst.best_iteration)\n",
    "        sub_preds[:,5] += bst.predict(test_1[feats], num_iteration=bst.best_iteration) / folds.n_splits\n",
    "        # Make the feature importance dataframe\n",
    "        gain = bst.feature_importance('gain')\n",
    "        fold_importance_df = pd.DataFrame({'feature':bst.feature_name(),\n",
    "        'split':bst.feature_importance('split'),\n",
    "        'gain':100*gain/gain.sum(),\n",
    "        'fold':n_fold,\n",
    "        }).sort_values('gain',ascending=False)\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "#         print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx,0])))\n",
    "time.time()-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.701442 0.70563 0.699814 0.701301 0.706263"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(train_1['deal_or_not'], oof_preds.iloc[:,0]),roc_auc_score(train_1['deal_or_not'], oof_preds.iloc[:,1]),\n",
    "     roc_auc_score(train_1['deal_or_not'], oof_preds.iloc[:,2]),roc_auc_score(train_1['deal_or_not'], oof_preds.iloc[:,3]),\n",
    "       roc_auc_score(train_1['deal_or_not'], oof_preds.iloc[:,4]),roc_auc_score(train_1['deal_or_not'], oof_preds.iloc[:,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[:,1]=sub_preds[:,0]\n",
    "test.to_csv('submission1421_dartlrate1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = pd.DataFrame(oof_preds)\n",
    "a.to_pickle('oof_preds.pkl')\n",
    "\n",
    "b = pd.DataFrame(sub_preds)\n",
    "b.to_pickle('sub_preds.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds = pd.read_pickle('oof_preds.pkl')\n",
    "sub_preds = pd.read_pickle('sub_preds.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts=time.time()\n",
    "oof_pred = np.zeros(train_1.shape[0])\n",
    "sub_pred = np.zeros(test_1.shape[0])\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(pd.DataFrame(oof_preds), train_1['deal_or_not'])):\n",
    "    train_x, train_y = pd.DataFrame(oof_preds).iloc[train_idx], train_1['deal_or_not'].iloc[train_idx]\n",
    "    valid_x, valid_y = pd.DataFrame(oof_preds).iloc[valid_idx], train_1['deal_or_not'].iloc[valid_idx]\n",
    "    print(\"Train Index:\",train_idx,\",Val Index:\",valid_idx)\n",
    "    params = {\n",
    "        'nthread': 32,\n",
    "        'boosting_type': 'dart',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'learning_rate': 0.05,\n",
    "        'num_leaves': 15,\n",
    "        'max_depth': 4,\n",
    "        'feature_fraction': .9,\n",
    "        'bagging_fraction':0.6,\n",
    "        'bagging_freq':10,\n",
    "        'min_split_gain': 0.1,\n",
    "        'min_data_in_leaf': 100,\n",
    "        'min_child_weight': 0.01,\n",
    "        'reg_alpha': 10,\n",
    "        'reg_lambda': 10,\n",
    "    # parameters for dart\n",
    "    #     'drop_rate':0.1,\n",
    "    #     'skip_drop':0.5,\n",
    "    #     'max_drop':100\n",
    "    #     'uniform_drop':True,\n",
    "    #     'xgboost_dart_mode':True,\n",
    "    #     'drop_seed':4\n",
    "    }\n",
    "    if n_fold >= 0:\n",
    "        dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "        dval = lgb.Dataset(valid_x, label=valid_y, reference=dtrain)\n",
    "        \n",
    "        bst = lgb.train(\n",
    "        params, dtrain, num_boost_round=8000,\n",
    "        valid_sets=[dval], early_stopping_rounds=500, verbose_eval=200)\n",
    "        oof_pred[valid_idx] = bst.predict(valid_x, num_iteration=bst.best_iteration)\n",
    "        sub_pred += bst.predict(pd.DataFrame(sub_preds), num_iteration=bst.best_iteration) / folds.n_splits\n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_pred[valid_idx])))\n",
    "time.time()-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(train_1['deal_or_not'], oof_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[:,1]=sub_pred\n",
    "test.to_csv('submission1421_stacking_dart_參數.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.754755 0.760061 0.754866 0.758261 0.758392\n",
    "# 0.7570996115387698\n",
    "# params = {\n",
    "#     'nthread': 32,\n",
    "#     'boosting_type': 'dart',\n",
    "#     'objective': 'binary',\n",
    "#     'metric': 'auc',\n",
    "#     'learning_rate': 0.05,\n",
    "#     'num_leaves': 15,\n",
    "#     'max_depth': 4,\n",
    "#     'feature_fraction': .9,\n",
    "#     'bagging_fraction':0.6,\n",
    "#     'bagging_freq':10,\n",
    "#     'min_split_gain': 0.1,\n",
    "#     'min_data_in_leaf': 100,\n",
    "#     'min_child_weight': 0.01,\n",
    "#     'reg_alpha': 10,\n",
    "#     'reg_lambda': 10,\n",
    "# # parameters for dart\n",
    "# #     'drop_rate':0.1,\n",
    "# #     'skip_drop':0.5,\n",
    "# #     'max_drop':100\n",
    "# #     'uniform_drop':True,\n",
    "# #     'xgboost_dart_mode':True,\n",
    "# #     'drop_seed':4\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.754725 0.760029 0.754830 0.758150 0.758237\n",
    "# 0.7570709264350741\n",
    "#     'num_leaves': 15,$$\n",
    "#     'max_depth': 4,$$\n",
    "#     'feature_fraction': .9,$$\n",
    "#     'bagging_fraction':0.9,\n",
    "#     'bagging_freq':100,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.754716 0.760015 0.754880 0.758131 0.758209\n",
    "# 0.7569722112854734\n",
    "# params = {\n",
    "#     'nthread': 32,\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'objective': 'binary',\n",
    "#     'metric': 'auc',\n",
    "#     'learning_rate': 0.05,\n",
    "#     'num_leaves': 15,\n",
    "#     'max_depth': 4,\n",
    "#     'feature_fraction': .9,\n",
    "#     'bagging_fraction':0.9,\n",
    "#     'bagging_freq':100,\n",
    "#     'min_split_gain': 0.1,\n",
    "#     'min_data_in_leaf': 20,\n",
    "#     'min_child_weight': 0.01,\n",
    "#     'reg_alpha': 10,\n",
    "#     'reg_lambda': 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.754618 0.759785 0.754342 0.757714 0.758126\n",
    "# 0.7565652445288027\n",
    "#     'feature_fraction': .9,$$\n",
    "#     'bagging_fraction':0.9,\n",
    "#     'bagging_freq':100,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.754495 0.759810 0.754173 0.757745 0.758077\n",
    "# 0.7556803729754726\n",
    "#     'feature_fraction': .9,$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.754492 0.759718 0.754349 0.757744 0.758124\n",
    "# 0.7545011673800177\n",
    "# params = {\n",
    "#     'nthread': 32,\n",
    "#     'boosting_type': 'dart',\n",
    "#     'objective': 'binary',\n",
    "#     'metric': 'auc',\n",
    "#     'learning_rate': 0.05,\n",
    "#     'num_leaves': 100,\n",
    "#     'max_depth': 8,\n",
    "#     'feature_fraction': 0.7,\n",
    "#     'min_split_gain': 0.1,\n",
    "#     'min_data_in_leaf': 100,\n",
    "#     'min_child_weight': 0.01,\n",
    "#     'reg_alpha': 10,\n",
    "#     'reg_lambda': 10 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.753232 0.757929 0.753538 0.755814 0.756462\n",
    "# 0.751736 0.755271 0.75038 0.753552 0.754325\n",
    "# 0.752523 0.757315 0.753433 0.756181 0.756143\n",
    "# 0.75104 0.755004 0.750773 0.753097 0.753949\n",
    "# 0.750171 0.7544 0.75046 0.753191 0.75456\n",
    "# 0.701442 0.70563 0.699814 0.701301 0.706263"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
